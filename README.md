# MLOps_Project
Final Project for MLOPS learning
---
This project serves as a capstone to the tutorial sessions taken concerning the work flow of Machine Learning Operations. 

In machine learning, once the dataset is acquired, MLOps Engineers typically go through the following steps
- Model Training
- Experiment Tracking
- Orchestration 
- Deployment 
- Monitoring

So let's go through my process at tackling this problem.

### The Dataset
After spending a weekend thinking of what dataset to use, finding my Eureka moment then later seeiing the potential flaws of using the chosen dataset, I decided to work on a simple and very common dataset that I had worked on in the past. I decided to go with a Wine Quality Dataset, where some characteristics of wine are gathered and matched to what professional wine taster deem to rate the selected wine.

Instead of splitting one dataset into train and test, I decided to get two different wine quality datasets to use for each. I wanted the training dataset to be as big as possible to improve the model.

I got both my datasets from kaggle, this is the link;

- Training Set: https://www.kaggle.com/datasets/subhajournal/wine-quality-data-combined

- Validation Set: https://www.kaggle.com/datasets/rajyellow46/wine-quality 


### 1. Model Training

Before we even start the project, if you're starting from scratch then you might want to get Python installed and create a virtual environment for this.

#### - Packages
For the packages and libraies used for this particular section, we would have to ```pip install``` them. Primarily;

- ```pandas``` for data manipulation
- ```matplotlib``` and ```seaborn``` for data visualization
- ```sklearn``` for model training

#### - Inspecting the Data

Following the code in the repository, I loaded the training data and examined it. A few interesting things and be gathered from the output below which was achieved by the following code 
```python 
wine_train_df.isnull().sum()
```
The output:
```
type                    0
fixed_acidity           0
volatile_acidity        0
citric_acid             0
residual_sugar          0
chlorides               0
free_sulfur_dioxide     0
total_sulfur_dioxide    0
density                 0
pH                      0
sulphates               0
alcohol                 0
quality                 0
dtype: int64
```

Frome the out put, there are no null values (a good thing). As much as this data looks almost perfect, there was a problem.


On a closer look at the data, we can see that almost all the columns are numerical except ```type```. Numerical data is crucial when it comes to working with Machine Learning Models.

To fix this problem, I changed the values of the ```type``` column from **categorical** to **numerical** using *One Hot Encoding*


```python
from sklearn.preprocessing import OneHotEncoder

#encoding the wine types as 1 and 0 with respect to red to be computated

encoder = OneHotEncoder(sparse=False)

encode_types = encoder.fit_transform(wine_train_df['type'].values.reshape(-1, 1))
encode_types
```

the code above changes the values in the ```type``` column from white and red to 1 and 0. Now red wine will be represented as 1 and white wine as 0


#### - Training

After we have gotten the data ready, the fun part begins, *Model Training*. 

Training the model wasn't as easy as I thought. The process was pretty straight forward but my issue came from the results, they were pretty bad and not even close to accurate but as suggested by my mentor, I read a few research papers concerning the topic and they helped a lot. Not only did they suggest better models to use but they also came up with better methods.
    
I initially, removed most of the columns kept the ones that mostly affected the quality of wine (which were not many) according to the heatmap below, which was also generated by my code

![](images/heatmap.png)

I even tried to combine some of them to make new columns. But the research papers used all of them and they got better results so I went down that route. I also had to split my data into independent variables and dependent variables(target variables)


Now that I had my data ready, I begun the training. Through my research, I picked 5 models to use and this was the outcome on the training set.

    RandomForestRegressor
    RMSE:  {0.027071980054071056}
    Accuracy:  {0.999037171881531}
---
    RandomForestClassifier
    RMSE:  {0.0}
    Accuracy:  {1.0}
---
    ExtraTreesClassifier
    RMSE:  {0.0}
    Accuracy:  {1.0}
---
    DecisionTreeClassifier
    RMSE:  {0.0}
    Accuracy:  {1.0}
---
    KNeighborsRegressor
    RMSE:  {0.16338349530598967}
    Accuracy:  {0.9649308622642955}

**Now hold on**, let's not get too excited yet. Yes, these results look pretty impressive. Most of them are perfect but let's not forget that we haven't tested our model on the validation dataset yet.


#### - Validation

Now that we have our models trained, let's bring in the validation set. To avoid going through whole data investigation thing with the second dataset, I made it simple function to do it for me.

```python
def read_dafaframe(filename):
    df = pd.read_csv(filename)

    encoder = OneHotEncoder(sparse=False)

    encoded_types = encoder.fit_transform(df['type'].values.reshape(-1, 1))

    label= ['red','white']
    wine_types = pd.DataFrame(encoded_types, columns= label)

    df['red_wine'] = wine_types['red']

    return df
```


On working with the second dataset, I noticed something.

    #   Column                Non-Null Count  Dtype  
    ---  ------                --------------  -----  
    0   type                  6497 non-null   object 
    1   fixed_acidity         6487 non-null   float64
    2   volatile_acidity      6489 non-null   float64
    3   citric_acid           6494 non-null   float64
    4   residual_sugar        6495 non-null   float64
    5   chlorides             6495 non-null   float64
    6   free_sulfur_dioxide   6497 non-null   float64
    7   total_sulfur_dioxide  6497 non-null   float64
    8   density               6497 non-null   float64
    9   pH                    6488 non-null   float64
    10  sulphates             6493 non-null   float64
    11  alcohol               6497 non-null   float64
    12  quality               6497 non-null   int64  
    13  red_wine              6497 non-null   float64

If you take a look at the Non-Null Count column, you will see that our data has some null values in there.

There are different ways to deal with null values depending on the dataset. You can fill them with the mean value, fill them with 0 or remove those rows completely but the last method will result in other data being lost. 

Based on the dataset, I decided to fill them with the mean values 

```python
#filling in the mean values

for col, value in validation_df.items():
 if col != 'type':
    validation_df[col] = validation_df[col].fillna(validation_df[col].mean())
validation_df.isnull().sum()
```

Now that the second dataset is ready, let's test out our models on it. I dropped out decision tree to have fewer models to filter out in the next stage of the project

    RandomForestRegressor
    RMSE: 0.08215843046127176
    Accuracy: 0.9911470362380227
---
    RandomForestClassifier
    RMSE: 0.06681016826772575
    Accuracy: 0.9941457731172564
---
    ExtraTreesClassifier
    RMSE:  0.0632601533851334
    Accuracy:  0.9947513827947816
---
    KNeighborsRegressor
    RMSE: 0.260202026623686
    Accuracy: 0.9112014716834054


Well there you have it. These results aren't as perfect as the ones before but they are still super accurate. Great, our models are ready for the next stage, Experiment Tracking

### 2. Experiment Tracking